# gpt-file-querry-aws

This is a project for creating the gpt-file-querry logic over AWS Lambda.

The gpt-file-querry is using llama-index with llama-hub loaders for documents
,and azure_vision and openAI for images. 

This project started by following the AWS Sam [tutorial](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-getting-started-hello-world.html)
Then adding the gpt-file-querry logic.

The project also utilizes two lambda-layers to allow the llama-index package to be used in the lambda function.
The main module is the hello_world.

The packages present in these layers are stated in the hello_world/layers-requirements.txt file.

## Current status of the project
There are two main issues with the current state of the project:
- For image files, the file format is not compatible with the azure vision api, and the analyze fails.
  When Used with the  vanilla flask, without awsgi, it works fine.
- For documents files, the download_loader is failing because it is trying to write to un-writable folder.
  It should be fixed by using the /tmp folder (preferable) 
  or by downloading the loader directly from github for the following loaders : 
  - https://llamahub.ai/l/file-docx
  - https://llamahub.ai/l/file-pdf

## Deploy the sample application
```bash
sam sync --use-container
```

or 
```bash
sam build --use-container
sam deploy --guided
```



## Use the SAM CLI to build and test locally

Build your application with the `sam build --use-container` command.

```bash
gpt-file-querry$ sam build --use-container
```

The SAM CLI installs dependencies defined in `hello_world/requirements.txt`, creates a deployment package, and saves it in the `.aws-sam/build` folder.

Test a single function by invoking it directly with a test event. An event is a JSON document that represents the input that the function receives from the event source. Test events are included in the `events` folder in this project.

Run functions locally and invoke them with the `sam local invoke` command.

```bash
gpt-file-querry$ sam local invoke HelloWorldFunction --event events/event.json
```

The SAM CLI can also emulate your application's API. Use the `sam local start-api` to run the API locally on port 3000.

```bash
gpt-file-querry$ sam local start-api
gpt-file-querry$ curl http://localhost:3000/
```

The SAM CLI reads the application template to determine the API's routes and the functions that they invoke. The `Events` property on each function's definition includes the route and method for each path.

```yaml
      Events:
        HelloWorld:
          Type: Api
          Properties:
            Path: /hello
            Method: get
```

## Add a resource to your application
The application template uses AWS Serverless Application Model (AWS SAM) to define application resources. AWS SAM is an extension of AWS CloudFormation with a simpler syntax for configuring common serverless application resources such as functions, triggers, and APIs. For resources not included in [the SAM specification](https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md), you can use standard [AWS CloudFormation](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html) resource types.

## Fetch, tail, and filter Lambda function logs

To simplify troubleshooting, SAM CLI has a command called `sam logs`. `sam logs` lets you fetch logs generated by your deployed Lambda function from the command line. In addition to printing the logs on the terminal, this command has several nifty features to help you quickly find the bug.

`NOTE`: This command works for all AWS Lambda functions; not just the ones you deploy using SAM.

```bash
gpt-file-querry$ sam logs -n HelloWorldFunction --stack-name gpt-file-querry --tail
```

You can find more information and examples about filtering Lambda function logs in the [SAM CLI Documentation](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-logging.html).

## Tests

Tests are defined in the `tests` folder in this project. Use PIP to install the test dependencies and run tests.

```bash
gpt-file-querry$ pip install -r tests/layers-requirements.txt --user
# unit test
gpt-file-querry$ python -m pytest tests/unit -v
# integration test, requiring deploying the stack first.
# Create the env variable AWS_SAM_STACK_NAME with the name of the stack we are testing
gpt-file-querry$ AWS_SAM_STACK_NAME=<stack-name> python -m pytest tests/integration -v
```

## Cleanup

To delete the sample application that you created, use the AWS CLI. Assuming you used your project name for the stack name, you can run the following:

```bash
aws cloudformation delete-stack --stack-name gpt-file-querry
```

## Resources

See the [AWS SAM developer guide](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html) for an introduction to SAM specification, the SAM CLI, and serverless application concepts.

Next, you can use AWS Serverless Application Repository to deploy ready to use Apps that go beyond hello world samples and learn how authors developed their applications: [AWS Serverless Application Repository main page](https://aws.amazon.com/serverless/serverlessrepo/)
